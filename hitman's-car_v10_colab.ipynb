{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Welcome, To ~ \n",
        "#   The Hitman's car_______\"(0TYT=0> ______________version-10\n",
        "#___________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9EtcK5y1trT"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install deepface\n",
        "!pip install cmapy\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ~~ Setting Everything Up /...\n",
        "#________________________________________________________________________________________________\n",
        "#source_vid_path = \"/content/drive/MyDrive/Final-Task/Data/Obama-db/obamawalk.mp4\"\n",
        "#source_vid_path = \"data/workshop-vid.mp4\"\n",
        "#source_vid_path = \"data/obamawalk.mp4\"\n",
        "source_vid_path = 0\n",
        "#________________________________________________________________________________________________\n",
        "#vid_save_path = \"/content/drive/MyDrive/Final-Task/Data/Obama-db/obama-output.mp4\"\n",
        "vid_save_path = \"outputs/my_output.mp4\"\n",
        "#________________________________________________________________________________________________\n",
        "#target_face_path = \"/content/drive/MyDrive/Final-Task/Data/Obama-db/obama2.jpg\"\n",
        "#target_face_path = \"obama2.jpg\"\n",
        "target_face_path = \"me.jpg\"\n",
        "#________________________________________________________________________________________________\n",
        "#Sensitivity to recognized person's movements\n",
        "#sensitivity = 0.001    \n",
        "sensitivity = 0.0001\n",
        "#________________________________________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_qN6L4U91nBg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from deepface import DeepFace\n",
        "from deepface.commons import functions\n",
        "from deepface.detectors import FaceDetector\n",
        "from matplotlib import pyplot as plt\n",
        "import cmapy\n",
        "#from facenet_pytorch import InceptionResnetV1, MTCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hliL-92U1nBi"
      },
      "outputs": [],
      "source": [
        "# ~~ The deepface package ~~\n",
        "\n",
        "#Face detection ~\n",
        "backends = [\n",
        "  'opencv', \n",
        "  'ssd', \n",
        "  'dlib', \n",
        "  'mtcnn', \n",
        "  'retinaface', \n",
        "  'mediapipe'\n",
        "]\n",
        "\n",
        "#Face recognition ~\n",
        "models = [\n",
        "  \"VGG-Face\", \n",
        "  \"Facenet\", \n",
        "  \"Facenet512\", \n",
        "  \"OpenFace\", \n",
        "  \"DeepFace\", \n",
        "  \"DeepID\", \n",
        "  \"ArcFace\", \n",
        "  \"Dlib\", \n",
        "  \"SFace\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UxFHOlfa1nBi",
        "outputId": "7427e3fe-5115-4799-fe0f-e4e49620defc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https:\\github.com\\ultralytics\\assets\\releases\\download\\v0.0.0\\yolov8n.pt to yolov8n.pt...\n",
            "100%|██████████| 6.23M/6.23M [00:06<00:00, 1.08MB/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x23abea26150>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ~~ The Models used in this project ~~\n",
        "\n",
        "#Objct detection - to detect people---------------------------------------------#\n",
        "#seg_model = YOLO('yolov8n-seg.pt')\n",
        "yolo_model = YOLO('yolov8n.pt')\n",
        "\n",
        "#Face detection ~ --------------------------------------------------------------#\n",
        "face_detector = FaceDetector.build_model('ssd')\n",
        "'''face_detector = MTCNN(\n",
        "    image_size=299, \n",
        "    margin=40, \n",
        "    min_face_size=20,\n",
        "    keep_all=False,\n",
        "    )'''\n",
        "\n",
        "#Face recognition ~ -----------------------------------------------------------#\n",
        "DeepFace.build_model('SFace')\n",
        "DeepFace.build_model('Facenet512')\n",
        "#face_recognizer = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Iko0RG0B1nBj",
        "outputId": "53ccbc5a-0fac-42f4-c955-811678836b18"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading weights:  None\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n",
            "Using cache found in C:\\Users\\HP/.cache\\torch\\hub\\intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "# ~~ MiDaS - Depth Estimation ~~\n",
        "\n",
        "model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"DPT_Large\"     # MiDaS v3 - Large     \n",
        "\n",
        "# Download model if not yet downloaded\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
        "\n",
        "# Set torch options\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "# Load transforms for each model\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "# Select transforms\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yB4Y5Rdw1nBj",
        "outputId": "ebcdfe88-833a-4a20-a3ea-8142c8703447"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ndef cosine(emb1, emb2):\\n    cos = np.dot(emb1, emb2.T) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\\n    return cos'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def yolov8(frame):\n",
        "    results = yolo_model.predict(\n",
        "        source = frame,\n",
        "        \n",
        "        conf = 0.5,\n",
        "        iou = 0.7,\n",
        "        show = False,\n",
        "        save = False,\n",
        "        retina_masks = True,\n",
        "        classes = 0,\n",
        "    )\n",
        "    return results\n",
        "\n",
        "def get_cropped_people(results, frame):\n",
        "    '''\n",
        "    results is from yolov8\n",
        "    Returns list of cropped images of persons, and corresponding list of their top left coordinates\n",
        "    '''\n",
        "    im_list = []\n",
        "    coordi_list = []\n",
        "    area_list = []\n",
        "    for result in results:\n",
        "        for box in result.boxes:\n",
        "            for a, b, c, d in box.xyxy:\n",
        "                x1 = int(a)\n",
        "                y1 = int(b)\n",
        "                x2 = int(c)\n",
        "                y2 = int(d)\n",
        "            croppped = frame[y1:y2, x1:x2]\n",
        "            area_list.append((x2-x1)*(y2-y1))\n",
        "            im_list.append(croppped)\n",
        "            \n",
        "            '''x = (x1 + x2)/2\n",
        "            y = (y1 + y2)/2'''\n",
        "            coordi_list.append((x1, y1))\n",
        "    return im_list, coordi_list, area_list\n",
        "\n",
        "def get_cropped_faces(people_list, coordi_list, area_list):\n",
        "    '''\n",
        "    people_list is from get_cropped_people\n",
        "    Returns list of cropped images of faces \n",
        "    & corrsponding list of bounding boxes in main frame\n",
        "    '''\n",
        "    face_list = []\n",
        "    bounding_box_list = []\n",
        "    new_area_list = []\n",
        "\n",
        "    for i, person in enumerate(people_list):\n",
        "\n",
        "        x_person, y_person = coordi_list[i]\n",
        "        area = area_list[i]\n",
        " \n",
        "        if person.shape[0] == 0 or person.shape[1] == 0 or person is None:\n",
        "            continue\n",
        "        try:       \n",
        "            face_objs = FaceDetector.detect_faces(\n",
        "                face_detector = face_detector,\n",
        "                detector_backend = 'ssd',\n",
        "                img = person,\n",
        "                align = True,\n",
        "            )\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "        \n",
        "        if face_objs is None:\n",
        "            print('No face detected')\n",
        "            continue\n",
        "\n",
        "        test_count = 0\n",
        "        for im_obj in face_objs:\n",
        "            face, box, conf = im_obj\n",
        "            face_list.append(face)\n",
        "\n",
        "            '''print('Face detected')\n",
        "            \n",
        "            print(box)\n",
        "            print(test_count)\n",
        "            test_count += 1'''\n",
        "\n",
        "            \n",
        "            '''cv.imshow('face', face)\n",
        "            cv.waitKey(0)\n",
        "            cv.destroyAllWindows()'''\n",
        "            \n",
        "            x1 = int(box[0])\n",
        "            y1 = int(box[1])\n",
        "            x2 = int(box[0] + box[2])\n",
        "            y2 = int(box[1] + box[3])\n",
        "\n",
        "            bounding_box_p1 = (\n",
        "                x_person + x1,\n",
        "                y_person + y1,\n",
        "            )\n",
        "            bounding_box_p2 = (\n",
        "                x_person + x2,\n",
        "                y_person + y2,\n",
        "            )\n",
        "            #print(bounding_box_p1, bounding_box_p2)\n",
        "            bounding_box_list.append((bounding_box_p1, bounding_box_p2))\n",
        "\n",
        "            #Area of the person-box from yolo, corresponding to this (i'th) face\n",
        "            new_area_list.append(area)\n",
        "            \n",
        "    return face_list, bounding_box_list, new_area_list\n",
        "\n",
        "\n",
        "def get_depth(img):\n",
        "    input_batch = transform(img).to(device)\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    output = prediction.cpu().numpy()\n",
        "\n",
        "    output /= output.max()\n",
        "    output *= 255\n",
        "    output = output.astype(np.uint8)\n",
        "    output = cv.applyColorMap(output, cmapy.cmap('magma'))\n",
        "\n",
        "    return output\n",
        "\n",
        "def face_recognition(target_face, face_pic, model_name=\"Facenet\", detector_backend=\"skip\"):\n",
        "    result = DeepFace.verify(\n",
        "        target_face, \n",
        "        face_pic, \n",
        "        model_name, \n",
        "        detector_backend\n",
        "        )\n",
        "    return result\n",
        "\n",
        "def findCosineDistance(source_representation, test_representation):\n",
        "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
        "    b = np.sum(np.multiply(source_representation, source_representation))\n",
        "    c = np.sum(np.multiply(test_representation, test_representation))\n",
        "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
        "\n",
        "'''\n",
        "def cosine(emb1, emb2):\n",
        "    cos = np.dot(emb1, emb2.T) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
        "    return cos'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7yEajMG41nBk",
        "outputId": "490abc41-7e4b-46d7-dc7e-0c78031924b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cv.imshow(\\'target\\', target_face)\\ncv.waitKey(0)\\ncv.destroyAllWindows()\\n\\ntarget_rep = target_embd[0][\"embedding\"]'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#Get target face~ \n",
        "target_face = cv.imread(target_face_path)\n",
        "\n",
        "'''cv.imshow('target', target_face)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "target_rep = target_embd[0][\"embedding\"]'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VIrtnMca1nBk",
        "outputId": "4ebf61af-1d9c-4c23-bf80-d0a15fae2467"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 253.7ms\n",
            "Speed: 0.0ms preprocess, 253.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 225.4ms\n",
            "Speed: 1.0ms preprocess, 225.4ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 157.3ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 157.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 184.1ms\n",
            "Speed: 0.0ms preprocess, 184.1ms inference, 0.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 293.2ms\n",
            "Speed: 0.5ms preprocess, 293.2ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 157.1ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 157.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 151.0ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 151.0ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 157.5ms\n",
            "Speed: 1.4ms preprocess, 157.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 163.1ms\n",
            "Speed: 0.0ms preprocess, 163.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 156.3ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  0\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 156.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 154.8ms\n",
            "Speed: 7.6ms preprocess, 154.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 182.7ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 182.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 163.2ms\n",
            "Speed: 7.3ms preprocess, 163.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 163.0ms\n",
            "Speed: 0.0ms preprocess, 163.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 149.6ms\n",
            "Speed: 0.0ms preprocess, 149.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 175.5ms\n",
            "Speed: 0.0ms preprocess, 175.5ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 156.0ms\n",
            "Speed: 0.0ms preprocess, 156.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 139.9ms\n",
            "Speed: 0.0ms preprocess, 139.9ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 154.3ms\n",
            "Speed: 2.1ms preprocess, 154.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.702\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 159.7ms\n",
            "Speed: 0.0ms preprocess, 159.7ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 182.2ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 182.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 147.5ms\n",
            "Speed: 0.0ms preprocess, 147.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 156.0ms\n",
            "Speed: 0.0ms preprocess, 156.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 158.8ms\n",
            "Speed: 0.5ms preprocess, 158.8ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 174.2ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 174.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 149.8ms\n",
            "Speed: 1.0ms preprocess, 149.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 161.4ms\n",
            "Speed: 0.0ms preprocess, 161.4ms inference, 9.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 156.9ms\n",
            "Speed: 0.0ms preprocess, 156.9ms inference, 6.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 158.6ms\n",
            "Speed: 0.0ms preprocess, 158.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 142.2ms\n",
            "Speed: 0.0ms preprocess, 142.2ms inference, 5.6ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  1.98\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 165.3ms\n",
            "Speed: 2.1ms preprocess, 165.3ms inference, 4.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 158.9ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 158.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 2 persons, 154.5ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 3.5ms preprocess, 154.5ms inference, 8.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 (no detections), 145.3ms\n",
            "Speed: 0.0ms preprocess, 145.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 (no detections), 163.2ms\n",
            "Speed: 0.0ms preprocess, 163.2ms inference, 7.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 (no detections), 161.6ms\n",
            "Speed: 0.0ms preprocess, 161.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 (no detections), 165.8ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 165.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 (no detections), 161.0ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 161.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 (no detections), 185.4ms\n",
            "Speed: 0.0ms preprocess, 185.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 (no detections), 173.1ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.004\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 173.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 (no detections), 158.1ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 0.0ms preprocess, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 (no detections), 158.8ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 5.0ms preprocess, 158.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 (no detections), 160.9ms\n",
            "Speed: 0.0ms preprocess, 160.9ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 480x640 1 person, 152.3ms\n",
            "Speed: 0.0ms preprocess, 152.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 160.9ms\n",
            "Speed: 4.6ms preprocess, 160.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 161.7ms\n",
            "Speed: 0.0ms preprocess, 161.7ms inference, 2.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0: 480x640 1 person, 190.3ms\n",
            "Speed: 0.0ms preprocess, 190.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 480x640 1 person, 147.7ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n",
            "-0.0 %\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Speed: 4.0ms preprocess, 147.7ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FPS =  2.245\n"
          ]
        }
      ],
      "source": [
        "#Run the video, and go frame by frame ~\n",
        "#cap = cv.VideoCapture('workshop-vid.mp4')\n",
        "#cap = cv.VideoCapture('obama-biden.mp4')\n",
        "#cap = cv.VideoCapture('obama-bgface.mp4')\n",
        "#cap = cv.VideoCapture('obama-laterals-and-more.mp4')\n",
        "#cap = cv.VideoCapture('obamawalk.mp4')\n",
        "#cap = cv.VideoCapture(0)\n",
        "\n",
        "cap = cv.VideoCapture(source_vid_path)\n",
        "\n",
        "#FPS Calculation-----------------------------------------------------------------------------#\n",
        "frame_count = 0\n",
        "fps = 0\n",
        "\n",
        "#Video writer-------------------------------------------------------------------------------#\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))*2\n",
        "   \n",
        "size = (frame_width, frame_height)\n",
        "\n",
        "output = cv.VideoWriter(vid_save_path, \n",
        "                         cv.VideoWriter_fourcc(*'mp4v'),\n",
        "                         5, size)\n",
        "#--------------------------------------------------------------------------------------------#\n",
        "previous_area = -1\n",
        "\n",
        "#Main loop---------------------------------------------------------------------------------#\n",
        "tic = time.time()\n",
        "while True:\n",
        "    \n",
        "    ret, frame = cap.read()\n",
        "    frame_count = frame_count + 1\n",
        "\n",
        "    nextFrameNo = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
        "    totalFrames = cap.get(cv.CAP_PROP_FRAME_COUNT)\n",
        "    complete = nextFrameNo/totalFrames\n",
        "    print(complete*100, '%')\n",
        "\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    if np.any(frame) == False:\n",
        "        continue\n",
        "    \n",
        "    # Person detector---------------------------------------------------------------------------------#\n",
        "    results = yolov8(frame)\n",
        "    cropped_people, coordi_list, area_l = get_cropped_people(results, frame)\n",
        "    output_frame = results[0].plot() \n",
        "    \n",
        "    # Face detector------------------------------------------------------------------------------------#\n",
        "    if len(cropped_people) != 0:\n",
        "        face_list, bounding_boxes, person_areas = get_cropped_faces(cropped_people, coordi_list, area_l)\n",
        "        \n",
        "        #Boxes on faces\n",
        "        for i, face in enumerate(face_list):\n",
        "            p1, p2 = bounding_boxes[i]\n",
        "            #print('Drawing box', p1, p2)\n",
        "            cv.rectangle(output_frame, p1, p2, (0, 255, 255), 2)\n",
        "\n",
        "        #Face recognition--------------------------------------------------------------------------------#\n",
        "        face_model = \"SFace\"\n",
        "        \n",
        "        for i, face_pic in enumerate(face_list):\n",
        "            face = face_pic.copy()\n",
        "            if np.any(face) == False:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                result = face_recognition(\n",
        "                    target_face,\n",
        "                    face,\n",
        "                    model_name = face_model,\n",
        "                )\n",
        "                print(\"using - \", face_model)\n",
        "            except:\n",
        "                continue\n",
        "            \n",
        "\n",
        "            # We found our guy ??????????????\n",
        "            if (result['verified'] == True ):\n",
        "                p1, p2 = bounding_boxes[i]\n",
        "                cv.rectangle(output_frame, p1, p2, (255, 0, 20), 2)\n",
        "                #cv.putText(output_frame, 'found u!', p1, cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 20), 2, cv.LINE_AA)\n",
        "\n",
        "                if previous_area != -1:\n",
        "\n",
        "                    diff = person_areas[i] - previous_area\n",
        "\n",
        "                    threshold = frame.shape[0] * frame.shape[1] * sensitivity\n",
        "\n",
        "                    if diff > threshold:\n",
        "                        cv.putText(output_frame, 'Oh, You are approaching me?', p1, cv.FONT_HERSHEY_SIMPLEX, 1, (54, 255, 2), 2, cv.LINE_AA)\n",
        "                    elif diff < -threshold:\n",
        "                        cv.putText(output_frame, 'You going away?', p1, cv.FONT_HERSHEY_SIMPLEX, 1, (54, 255, 2), 2, cv.LINE_AA)\n",
        "                    else:\n",
        "                        cv.putText(output_frame, 'You not gonna move now?', p1, cv.FONT_HERSHEY_SIMPLEX, 1, (54, 255, 2), 2, cv.LINE_AA)\n",
        "                        \n",
        "                previous_area = person_areas[i]\n",
        "\n",
        "\n",
        "            '''face_embd = DeepFace.represent(\n",
        "                face,\n",
        "                model_name = 'Facenet',\n",
        "                detector_backend = 'skip',\n",
        "                )\n",
        "            \n",
        "            face_rep = face_embd[0][\"embedding\"]\n",
        "\n",
        "            cos_dist = findCosineDistance(target_rep, face_rep)'''\n",
        "\n",
        "\n",
        "            '''#Display each face\n",
        "                cv.imshow(\"Match\", face_pic)\n",
        "                \n",
        "                if cv.waitKey(1) & 0xFF == ord('m'):\n",
        "                    cap.release()\n",
        "                    cv.destroyAllWindows()\n",
        "                    exit()\n",
        "                cv.waitKey(0)\n",
        "                cv.destroyAllWindows()'''\n",
        "\n",
        "#------------------------------------------------------------------------------------------------#\n",
        "    #Depth map\n",
        "    depth = get_depth(frame)\n",
        "    #cv.imshow('depth', depth)\n",
        "    output_frame = np.concatenate((output_frame, depth), axis=0)\n",
        "#------------------------------------------------------------------------------------------------#\n",
        "    #Output ~\n",
        "\n",
        "    if frame_count%10 == 0:\n",
        "        toc = time.time()\n",
        "        fps = round((frame_count / (toc - tic)), 3)\n",
        "        frame_count = 0\n",
        "        tic = toc\n",
        "        \n",
        "    print('FPS = ', fps)\n",
        "    \n",
        "    cv.putText(\n",
        "        output_frame,\n",
        "        f'FPS: {fps}',\n",
        "        (10, 50),\n",
        "        cv.FONT_HERSHEY_SIMPLEX,\n",
        "        1,\n",
        "        (255, 0, 125),\n",
        "        2,\n",
        "        cv.LINE_AA,     \n",
        "    )\n",
        "\n",
        "    output.write(output_frame)\n",
        "    cv.imshow(\"Output\", output_frame)\n",
        "\n",
        "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "    \n",
        "\n",
        "cap.release()\n",
        "output.release()\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
